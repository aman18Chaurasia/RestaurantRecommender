{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8398b0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35d22f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_24812\\3490293822.py:2: DtypeWarning: Columns (15,16,18,19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  orders = pd.read_csv(f\"{base_path}/Train/orders.csv\")\n"
     ]
    }
   ],
   "source": [
    "base_path = \"data/assignment\"\n",
    "orders = pd.read_csv(f\"{base_path}/Train/orders.csv\")\n",
    "train_customers = pd.read_csv(f\"{base_path}/Train/train_customers.csv\")\n",
    "vendors = pd.read_csv(f\"{base_path}/Train/vendors.csv\")\n",
    "test_customers = pd.read_csv(f\"{base_path}/Test/test_customers.csv\")\n",
    "test_locations = pd.read_csv(f\"{base_path}/Test/test_locations.csv\")\n",
    "sample_submission = pd.read_csv(f\"{base_path}/SampleSubmission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f92cb0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orders columns: ['order_id', 'customer_id', 'item_count', 'grand_total', 'payment_mode', 'promo_code', 'vendor_discount_amount', 'promo_code_discount_percentage', 'is_favorite', 'is_rated', 'vendor_rating', 'driver_rating', 'deliverydistance', 'preparationtime', 'delivery_time', 'order_accepted_time', 'driver_accepted_time', 'ready_for_pickup_time', 'picked_up_time', 'delivered_time', 'delivery_date', 'vendor_id', 'created_at', 'LOCATION_NUMBER', 'LOCATION_TYPE', 'CID X LOC_NUM X VENDOR']\n",
      "train_customers columns: ['customer_id', 'gender', 'dob', 'status', 'verified', 'language', 'created_at', 'updated_at']\n"
     ]
    }
   ],
   "source": [
    "print(\"orders columns:\", orders.columns.tolist())\n",
    "print(\"train_customers columns:\", train_customers.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1bb93bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'authentication_id', 'latitude', 'longitude',\n",
      "       'vendor_category_en', 'vendor_category_id', 'delivery_charge',\n",
      "       'serving_distance', 'is_open', 'OpeningTime', 'OpeningTime2',\n",
      "       'prepration_time', 'commission', 'is_haked_delivering',\n",
      "       'discount_percentage', 'status', 'verified', 'rank', 'language',\n",
      "       'vendor_rating', 'sunday_from_time1', 'sunday_to_time1',\n",
      "       'sunday_from_time2', 'sunday_to_time2', 'monday_from_time1',\n",
      "       'monday_to_time1', 'monday_from_time2', 'monday_to_time2',\n",
      "       'tuesday_from_time1', 'tuesday_to_time1', 'tuesday_from_time2',\n",
      "       'tuesday_to_time2', 'wednesday_from_time1', 'wednesday_to_time1',\n",
      "       'wednesday_from_time2', 'wednesday_to_time2', 'thursday_from_time1',\n",
      "       'thursday_to_time1', 'thursday_from_time2', 'thursday_to_time2',\n",
      "       'friday_from_time1', 'friday_to_time1', 'friday_from_time2',\n",
      "       'friday_to_time2', 'saturday_from_time1', 'saturday_to_time1',\n",
      "       'saturday_from_time2', 'saturday_to_time2', 'primary_tags',\n",
      "       'open_close_flags', 'vendor_tag', 'vendor_tag_name', 'one_click_vendor',\n",
      "       'country_id', 'city_id', 'created_at', 'updated_at', 'device_type',\n",
      "       'display_orders'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(vendors.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bab7115b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Merge for positive samples\n",
    "orders[\"vendor_id\"] = orders[\"vendor_id\"].astype(str)\n",
    "vendors[\"id\"] = vendors[\"id\"].astype(str)\n",
    "\n",
    "df_pos = orders.merge(train_customers, on=\"customer_id\", how=\"left\")\n",
    "df_pos = df_pos.merge(vendors, left_on=\"vendor_id\", right_on=\"id\", how=\"left\")\n",
    "df_pos[\"target\"] = 1\n",
    "df_pos = df_pos[[\"customer_id\", \"LOCATION_NUMBER\", \"vendor_id\", \"target\"]]\n",
    "df_pos.columns = [\"CID\", \"LOC_NUM\", \"VENDOR\", \"target\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2dcfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Create negative samples (Fixed)\n",
    "neg_samples = []\n",
    "for cid in unique_customers:\n",
    "    pos_vendors = df_pos[df_pos[\"CID\"] == cid][\"VENDOR\"].tolist()\n",
    "    available_neg_vendors = [v for v in unique_vendors if v not in pos_vendors]\n",
    "    \n",
    "    if len(available_neg_vendors) == 0:\n",
    "        continue  # skip this customer\n",
    "    \n",
    "    neg_size = min(5, len(available_neg_vendors))\n",
    "    neg_vendors = np.random.choice(available_neg_vendors, size=neg_size, replace=False)\n",
    "    \n",
    "    for v in neg_vendors:\n",
    "        neg_samples.append([cid, 0, v, 0])\n",
    "\n",
    "df_neg = pd.DataFrame(neg_samples, columns=[\"CID\", \"LOC_NUM\", \"VENDOR\", \"target\"])\n",
    "df_all = pd.concat([df_pos, df_neg], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da2d1a2e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 5. Encode categorical\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df_all[\u001b[33m\"\u001b[39m\u001b[33mCID\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mdf_all\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mCID\u001b[39m\u001b[33m\"\u001b[39m].astype(\u001b[33m\"\u001b[39m\u001b[33mcategory\u001b[39m\u001b[33m\"\u001b[39m).cat.codes\n\u001b[32m      3\u001b[39m df_all[\u001b[33m\"\u001b[39m\u001b[33mVENDOR\u001b[39m\u001b[33m\"\u001b[39m] = df_all[\u001b[33m\"\u001b[39m\u001b[33mVENDOR\u001b[39m\u001b[33m\"\u001b[39m].astype(\u001b[33m\"\u001b[39m\u001b[33mcategory\u001b[39m\u001b[33m\"\u001b[39m).cat.codes\n",
      "\u001b[31mNameError\u001b[39m: name 'df_all' is not defined"
     ]
    }
   ],
   "source": [
    "# 5. Encode categorical\n",
    "df_all[\"CID\"] = df_all[\"CID\"].astype(\"category\").cat.codes\n",
    "df_all[\"VENDOR\"] = df_all[\"VENDOR\"].astype(\"category\").cat.codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667e6f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Split\n",
    "X = df_all.drop(\"target\", axis=1)\n",
    "y = df_all[\"target\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba088c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mX\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b125900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 108478, number of negative: 109703\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014827 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 374\n",
      "[LightGBM] [Info] Number of data points in the train set: 218181, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497193 -> initscore=-0.011229\n",
      "[LightGBM] [Info] Start training from score -0.011229\n",
      "ROC AUC: 0.8547388857039672\n"
     ]
    }
   ],
   "source": [
    "# 7. Model\n",
    "model = LGBMClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict_proba(X_test)[:, 1]\n",
    "roc_auc = roc_auc_score(y_test, preds)\n",
    "print(\"ROC AUC:\", roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94187532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to model/lgbm_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.makedirs(\"model\", exist_ok=True)  # Creates the 'model' folder if it doesn't exist\n",
    "\n",
    "import joblib\n",
    "joblib.dump(model, \"model/lgbm_model.pkl\")\n",
    "print(\"Model saved to model/lgbm_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201ecdee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to model/lgbm_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model, \"model/lgbm_model.pkl\")\n",
    "print(\"Model saved to model/lgbm_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f803a8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted probability of interaction: 0.9999\n"
     ]
    }
   ],
   "source": [
    "# predict.py\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "model = joblib.load(\"model/lgbm_model.pkl\")\n",
    "\n",
    "# Example input\n",
    "sample = pd.DataFrame([{\n",
    "    \"vendor_rating\": 4.5,\n",
    "    \"deliverydistance\": 3.2,\n",
    "    \"preparationtime\": 15\n",
    "}])\n",
    "\n",
    "prediction = model.predict_proba(sample)[:, 1][0]\n",
    "print(f\"Predicted probability of interaction: {prediction:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c780b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ submission.csv generated successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# 1. Load sample submission\n",
    "sample_df = pd.read_csv(\"SampleSubmission.csv\")\n",
    "\n",
    "# 2. Load trained model\n",
    "model = joblib.load(\"model/lgbm_model.pkl\")\n",
    "\n",
    "# 3. Extract features used during training\n",
    "# Make sure these match your actual model training features\n",
    "sample_df[\"CID\"] = sample_df[\"CID X LOC_NUM X VENDOR\"].apply(lambda x: x.split(\" X \")[0])\n",
    "sample_df[\"LOC_NUM\"] = sample_df[\"CID X LOC_NUM X VENDOR\"].apply(lambda x: int(x.split(\" X \")[1]))\n",
    "sample_df[\"VENDOR\"] = sample_df[\"CID X LOC_NUM X VENDOR\"].apply(lambda x: int(x.split(\" X \")[2]))\n",
    "\n",
    "# Select same features as in training\n",
    "features = [\"CID\", \"LOC_NUM\", \"VENDOR\"]\n",
    "\n",
    "# Encode categorical customer IDs to match training format\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "cid_encoder = LabelEncoder()\n",
    "sample_df[\"CID\"] = cid_encoder.fit_transform(sample_df[\"CID\"])\n",
    "\n",
    "X_sub = sample_df[features]\n",
    "\n",
    "# 4. Predict probabilities\n",
    "sample_df[\"target\"] = model.predict_proba(X_sub)[:, 1]\n",
    "\n",
    "# 5. Keep only required columns and save\n",
    "submission = sample_df[[\"CID X LOC_NUM X VENDOR\", \"target\"]]\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(\"✅ submission.csv generated successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a23e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 108478, number of negative: 109703\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012632 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 374\n",
      "[LightGBM] [Info] Number of data points in the train set: 218181, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497193 -> initscore=-0.011229\n",
      "[LightGBM] [Info] Start training from score -0.011229\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model/lgbm_model.pkl']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import joblib\n",
    "\n",
    "model = lgb.LGBMClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "joblib.dump(model, \"model/lgbm_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5b35be",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodel\u001b[49m.feature_name_)\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "print(model.feature_name_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
